---
title: "muonphysics"
author: "Kevin Robb"
date: "11/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r read_data}
# read in data
muondata_10.30 <- read.csv("C:/Users/kevin/Dropbox/OU/homeworks/A Lab/Lab 3 - Muon Physics/Data/19-10-30-16-34.data", sep="", stringsAsFactors=FALSE, header=FALSE)
muondata_11.18 <- read.csv("C:/Users/kevin/Dropbox/OU/homeworks/A Lab/Lab 3 - Muon Physics/Data/19-11-18-17-55.data", sep="", stringsAsFactors=FALSE, header=FALSE)
# combine data files
muondata <- rbind(muondata_10.30, muondata_11.18)
# give columns names
# first column is lifetime and second is time since 1970. only first column is important.
colnames(muondata) = c("Lifetime","Index")

# remove lines with lifetime >=40000 because not a successor event.
# will still contain accidental coincidences, so deal with that later.
# divide by 1000 to get in microseconds
lifetimes = subset(muondata, Lifetime<40000)$Lifetime/1000
#head(lifetimes)
num_lines = length(lifetimes)
num_lines

#plot the raw data in the range we care about
#png("raw_data.png", width=500, height=350) #open the file
plot(lifetimes,col="black",pch=16,cex=0.7, ylab="Lifetime (microseconds)") #,xaxt='n',xlab=""
#dev.off() #close file
```

```{r bin}
data_max = 20
num_bins = 100
bin_size = data_max/num_bins

#hist(lifetimes) #can't use this because we need the data of frequency per bin and to vary bin size
#bin_mins and bin_maxes correspond to borders of bins
bin_mins = seq(0, data_max - bin_size, by = bin_size)
bin_maxes = seq(bin_size, data_max, by = bin_size)
#keeps track of frequencies in each bin
bin_counts = matrix(NA,nr=data_max/num_bins,nc=0,byrow=TRUE)
  
#mat=matrix(NA,nr=1,nc=num_lines/numbins,byrow=TRUE)
for(i in 1:num_lines){
  for(b in 1:num_bins){
    if(lifetimes[i] > bin_mins[b] && lifetimes[i] < bin_maxes[b]){
      if(is.na(bin_counts[b])){
        bin_counts[b] = 1
      }
      else {
        bin_counts[b] = bin_counts[b] + 1
      }
    }
  }
}

binned_df <- data.frame("Time" = (bin_mins+bin_maxes)/2, "Frequency" = bin_counts)
# remove first bin from the data. timing limitation of our apparatus: doesn't get good data at short times
binned_df = binned_df[-1,]
#summary(binned_df)

# Store plot in image file
#png("binned_data.png", width=500, height=350) #open the file

x = barplot(t(as.matrix(binned_df$Frequency)), beside=TRUE, col="blue", xlab="Lifetime (microseconds)", ylab="Frequency", ylim=c(0,1.75*bin_counts[1]), xlim=c(0,200),) + axis(1,tick=TRUE,at=c(0,50,100,150,200),labels=c(0,5,10,15,20))

#dev.off() #close the file
```

```{r fit}
t = binned_df$Time
N = binned_df$Frequency

#run fitting function
fit = nls(N~B*exp(-1*t/tau)+A, start=list(B=3.1,tau=2,A=0.05))
summary(fit)


#create image file to store plot in
#png("fitted_data.png", width=500, height=350) #open the file

# make the graph. plot the points first
plot(t,N, col="black",pch=16,cex=0.7, xlim=c(0,data_max),ylim=c(0,1.75*bin_counts[1]), xlab="Time (microseconds)",ylab="Frequency")

# error bars
sdev = sqrt(N)
arrows(t, N-sdev, t, N+sdev, length=0.02, angle=90, code=3)
# actual prediction
#lines(t,predict(fit),col="red")
# hard set values to make smoother plot
B = summary(fit)$coefficients[1,1]
tau = summary(fit)$coefficients[2,1]
A = summary(fit)$coefficients[3,1]
#B = 2061.608 
#tau = 2039.113 
#A = 8.690 
t<-seq(0,200)
lines(t,B*exp(-1*t/tau)+A, col="blue")

#dev.off() #close the file
```

```{r loglog}
t = binned_df$Time
N = binned_df$Frequency

logt = log(t)
logN = log(N)

#create image file to store plot in
#png("log_data.png", width=500, height=350) #open the file

plot(logt,logN,col="black",pch=16,cex=0.7,xlab="Log(Time)",ylab="Log(Frequency)")

#run fitting function on linear part only
#fit = nls(N~B*exp(-1*t/tau)+A, start=list(B=1,tau=2000,A=50))
#fit = lm(logN[7:8]~logt[7:8])
#summary(fit)
#plot(logt,logt * -1*summary(fit)$coefficients[1,2] + summary(fit)$coefficients[1,1] - 3)

#dev.off() #close the file
```


```{r logplot_tau_flat}
#tau_df = -1 * binned_df$Time / log(binned_df$Frequency/B,base=exp(1))

log_df = data.frame("Time" = binned_df$Time, "Frequency" = binned_df$Frequency, "Logfreq"=log(binned_df$Frequency,base=exp(1)), "Tau" = -1 * binned_df$Time / log(binned_df$Frequency/B,base=exp(1)))

# save image
#png("tau_values.png", width=500, height=350) #open the file

#add points for tau calculated in each bin
plot(log_df$Time, log_df$Tau,col="black",pch=16,cex=0.7,xlab="Time (microseconds)",ylab="Muon Lifetime (microseconds)",ylim=c(0,5))
#put in paper as argument for why cutoff time matters. levels out at muon lifetime, then steadily increases at low constant rate as time goes on due to higher ratio of background as we go

# add flat line at calculated true lifetime tau
# tau comes from fitting function summary
abline(h=tau,col="blue")

#dev.off() #close the file
```

```{r coincidences}
# formula for predicted percent of data that are coincidences rather than true points we want
muon_rate = binned_df$Frequency
T = binned_df$Time
#bin_size

#png("coincidences.png", width=500, height=350) #open the file

plot(T, muon_rate^{-2} * T * bin_size, xlim=c(0,20),xlab="Time (microseconds)",ylab="Percent accidental coincidences",col="dark red",pch=16,cex=0.7)

#dev.off() #close file
```



